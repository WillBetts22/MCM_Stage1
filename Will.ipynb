{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460f3819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " identified 109 'Regular' countries (Active Winners).\n",
      "Split complete. Created 'data_bucket_A_regulars.csv' and 'data_bucket_B_underdogs.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Data\n",
    "df = pd.read_csv('summerOly_medal_counts.csv')\n",
    "\n",
    "# 2. Data Cleaning & Standardization (Crucial for the Paper)\n",
    "# The paper specifies merging specific historical entities.\n",
    "# We map Soviet Union/ROC to Russia, and East/West Germany to Germany.\n",
    "country_mapping = {\n",
    "    'Soviet Union': 'Russia',\n",
    "    'ROC': 'Russia',           # Russian Olympic Committee (2020)\n",
    "    'Unified Team': 'Russia',  # 1992 Transitional Team\n",
    "    'East Germany': 'Germany',\n",
    "    'West Germany': 'Germany'\n",
    "}\n",
    "\n",
    "# Create a clean copy and apply the mapping\n",
    "df_clean = df.copy()\n",
    "df_clean['NOC'] = df_clean['NOC'].replace(country_mapping)\n",
    "\n",
    "# 3. Remove 1906 Intercalated Games (if present) as per paper rules\n",
    "df_clean = df_clean[df_clean['Year'] != 1906]\n",
    "\n",
    "# 4. Identify \"Regulars\"\n",
    "# Definition: Any country that won at least 1 medal in the last two cycles (2020 or 2024).\n",
    "recent_cycles = [2020, 2024]\n",
    "recent_data = df_clean[df_clean['Year'].isin(recent_cycles)]\n",
    "\n",
    "# Group by Country (NOC) and see if they have medals\n",
    "# (Note: Your dataset only contains winners, so anyone in the 2020/2024 rows is a Regular)\n",
    "regular_countries_list = recent_data['NOC'].unique()\n",
    "\n",
    "print(f\" identified {len(regular_countries_list)} 'Regular' countries (Active Winners).\")\n",
    "\n",
    "# 5. Split the Dataset\n",
    "# Bucket A: Regulars (Historical data for current winners)\n",
    "df_regulars = df_clean[df_clean['NOC'].isin(regular_countries_list)]\n",
    "\n",
    "# Bucket B: Underdogs (Historical data for countries that didn't win recently)\n",
    "# This includes defunct nations (e.g., Yugoslavia) or countries currently in a drought.\n",
    "df_underdogs = df_clean[~df_clean['NOC'].isin(regular_countries_list)]\n",
    "\n",
    "# 6. Save the Output\n",
    "df_regulars.to_csv('data_bucket_A_regulars.csv', index=False)\n",
    "df_underdogs.to_csv('data_bucket_B_underdogs.csv', index=False)\n",
    "\n",
    "print(\"Split complete. Created 'data_bucket_A_regulars.csv' and 'data_bucket_B_underdogs.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db57be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. LOAD DATA WITH CORRECT ENCODING ---\n",
    "# We use encoding='cp1252' to handle special characters like \"•\"\n",
    "df_medals = pd.read_csv('summerOly_medal_counts.csv', encoding='cp1252')\n",
    "df_programs = pd.read_csv('summerOly_programs.csv', encoding='cp1252')\n",
    "df_athletes = pd.read_csv('summerOly_athletes.csv', encoding='cp1252')\n",
    "\n",
    "# If 'cp1252' still fails, try 'ISO-8859-1'\n",
    "# df_programs = pd.read_csv('summerOly_programs.csv', encoding='ISO-8859-1')\n",
    "\n",
    "print(\"Files loaded successfully!\")\n",
    "\n",
    "# --- CONTINUE WITH THE REST OF THE SCRIPT BELOW ---\n",
    "# ... (Paste the rest of the script from the previous step here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ae4532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n",
      "Success! Processed 1242 rows. Saved to 'final_model_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. LOAD DATA WITH ENCODING FIX ---\n",
    "# usage of encoding='cp1252' fixes the \"byte 0x95\" error\n",
    "df_medals = pd.read_csv('summerOly_medal_counts.csv', encoding='cp1252')\n",
    "df_programs = pd.read_csv('summerOly_programs.csv', encoding='cp1252')\n",
    "df_athletes = pd.read_csv('summerOly_athletes.csv', encoding='cp1252')\n",
    "\n",
    "print(\"Files loaded successfully.\")\n",
    "\n",
    "# --- 2. STANDARDIZE COUNTRY NAMES ---\n",
    "# Map historical countries to modern equivalents so they match across files\n",
    "country_map = {\n",
    "    'Soviet Union': 'Russia', 'URS': 'Russia', 'ROC': 'Russia', 'EUN': 'Russia',\n",
    "    'East Germany': 'Germany', 'GDR': 'Germany',\n",
    "    'West Germany': 'Germany', 'FRG': 'Germany',\n",
    "    'United States': 'USA', 'Great Britain': 'GBR',\n",
    "    'China': 'CHN', 'Japan': 'JPN', 'France': 'FRA' \n",
    "    # Add more if you see mismatches in your specific data\n",
    "}\n",
    "\n",
    "def clean_country(df, col_name):\n",
    "    # Ensure column is string type before replacing\n",
    "    df[col_name] = df[col_name].astype(str).replace(country_map)\n",
    "    return df\n",
    "\n",
    "df_medals = clean_country(df_medals, 'NOC')\n",
    "df_athletes = clean_country(df_athletes, 'NOC')\n",
    "\n",
    "# --- 3. CALCULATE \"TOTAL EVENTS\" (Denominator for ER) ---\n",
    "# Clean the year columns (remove '*') and sum the event counts\n",
    "year_cols = [c for c in df_programs.columns if c.replace('*','').strip().isdigit()]\n",
    "total_events_map = {}\n",
    "\n",
    "for year in year_cols:\n",
    "    clean_year = int(year.replace('*','').strip())\n",
    "    # Convert '•' or other non-numbers to 0, then sum\n",
    "    col_data = pd.to_numeric(df_programs[year], errors='coerce').fillna(0)\n",
    "    total_events_map[clean_year] = col_data.sum()\n",
    "\n",
    "# --- 4. CALCULATE \"COUNTRY PARTICIPATION\" (Numerator for ER & NA) ---\n",
    "# Group athletes by Year + Country to get counts\n",
    "country_stats = df_athletes.groupby(['Year', 'NOC']).agg({\n",
    "    'Event': 'nunique',  # Count unique events entered\n",
    "    'Name': 'nunique'    # Count unique athletes (NA)\n",
    "}).reset_index().rename(columns={'Event': 'Events_Participated', 'Name': 'NA'})\n",
    "\n",
    "# --- 5. MERGE EVERYTHING INTO THE MASTER TABLE ---\n",
    "# Start with medal winners\n",
    "df_master = df_medals.merge(country_stats, on=['Year', 'NOC'], how='left')\n",
    "\n",
    "# Fill NaNs (if a country won medals but has no athlete data, assume 0 or missing)\n",
    "df_master['Events_Participated'] = df_master['Events_Participated'].fillna(0)\n",
    "df_master['NA'] = df_master['NA'].fillna(0)\n",
    "\n",
    "# Calculate ER (Participation Rate)\n",
    "def calc_er(row):\n",
    "    y = row['Year']\n",
    "    # Avoid division by zero\n",
    "    if y in total_events_map and total_events_map[y] > 0:\n",
    "        return row['Events_Participated'] / total_events_map[y]\n",
    "    return 0\n",
    "\n",
    "df_master['ER'] = df_master.apply(calc_er, axis=1)\n",
    "\n",
    "# --- 6. CALCULATE HOST EFFECT (HE) ---\n",
    "# Map Host City to Country Code (Update this list based on your data's NOC codes)\n",
    "hosts = {\n",
    "    2028: 'USA', 2024: 'FRA', 2020: 'JPN', 2016: 'BRA', \n",
    "    2012: 'GBR', 2008: 'CHN', 2004: 'GRE', 2000: 'AUS',\n",
    "    1996: 'USA', 1992: 'ESP', 1988: 'KOR', 1984: 'USA', \n",
    "    1980: 'Russia', 1976: 'CAN', 1972: 'Germany'\n",
    "}\n",
    "\n",
    "df_master['HE'] = df_master.apply(lambda x: 1 if hosts.get(x['Year']) == x['NOC'] else 0, axis=1)\n",
    "\n",
    "# --- 7. CALCULATE ATHLETIC PERFORMANCE (AP) ---\n",
    "# Weighted sum of medals from the LAST 2 Olympics\n",
    "df_master['Score'] = (df_master['Gold']*3) + (df_master['Silver']*2) + (df_master['Bronze']*1)\n",
    "\n",
    "# Sort by Country then Year to calculate lag\n",
    "df_master = df_master.sort_values(['NOC', 'Year'])\n",
    "\n",
    "# Shift 1 (Previous Games) and Shift 2 (Games before that)\n",
    "df_master['Score_Lag1'] = df_master.groupby('NOC')['Score'].shift(1).fillna(0)\n",
    "df_master['Score_Lag2'] = df_master.groupby('NOC')['Score'].shift(2).fillna(0)\n",
    "\n",
    "# AP = Sum of scores from last two games\n",
    "df_master['AP'] = df_master['Score_Lag1'] + df_master['Score_Lag2']\n",
    "\n",
    "# --- 8. MUNDLAK VARIABLES (Long-Term Averages) ---\n",
    "# Calculate the historical average for each country\n",
    "mundlak_ER = df_master.groupby('NOC')['ER'].mean().rename('Mundlak_ER')\n",
    "mundlak_NM = df_master.groupby('NOC')['Score'].mean().rename('Mundlak_NM')\n",
    "\n",
    "# Merge these back into the main table\n",
    "df_master = df_master.merge(mundlak_ER, on='NOC').merge(mundlak_NM, on='NOC')\n",
    "\n",
    "# --- 9. FINAL FILTER FOR \"REGULARS\" ---\n",
    "# Filter for countries that won at least 1 medal in 2020 or 2024\n",
    "recent_winners = df_master[df_master['Year'].isin([2020, 2024])]['NOC'].unique()\n",
    "df_regulars = df_master[df_master['NOC'].isin(recent_winners)].copy()\n",
    "\n",
    "# Add Constant column (needed for the math model later)\n",
    "df_regulars['Const'] = 1\n",
    "\n",
    "# Save to CSV\n",
    "df_regulars.to_csv('final_model_data.csv', index=False)\n",
    "print(f\"Success! Processed {len(df_regulars)} rows. Saved to 'final_model_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b27fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready: 'final_underdogs_data.csv' created with 3080 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. LOAD DATA (With Fix for Special Characters) ---\n",
    "# The 'cp1252' encoding fixes the crash caused by bullet points in the CSV\n",
    "df_medals = pd.read_csv('summerOly_medal_counts.csv', encoding='cp1252')\n",
    "df_programs = pd.read_csv('summerOly_programs.csv', encoding='cp1252')\n",
    "df_athletes = pd.read_csv('summerOly_athletes.csv', encoding='cp1252')\n",
    "\n",
    "# --- 2. STANDARDIZE COUNTRY NAMES ---\n",
    "# Ensure countries match across all three files\n",
    "country_map = {\n",
    "    'Soviet Union': 'Russia', 'URS': 'Russia', 'ROC': 'Russia', 'EUN': 'Russia',\n",
    "    'East Germany': 'Germany', 'GDR': 'Germany', 'West Germany': 'Germany', 'FRG': 'Germany',\n",
    "    'United States': 'USA', 'Great Britain': 'GBR', 'China': 'CHN', 'Japan': 'JPN', 'France': 'FRA'\n",
    "}\n",
    "\n",
    "def clean_country(df, col_name):\n",
    "    df[col_name] = df[col_name].astype(str).replace(country_map)\n",
    "    return df\n",
    "\n",
    "df_medals = clean_country(df_medals, 'NOC')\n",
    "df_athletes = clean_country(df_athletes, 'NOC')\n",
    "\n",
    "# --- 3. CALCULATE \"TOTAL EVENTS\" (Denominator for ER) ---\n",
    "# Clean columns and sum up total events available per year\n",
    "year_cols = [c for c in df_programs.columns if c.replace('*','').strip().isdigit()]\n",
    "total_events_map = {}\n",
    "for year in year_cols:\n",
    "    clean_year = int(year.replace('*','').strip())\n",
    "    # Force non-numeric characters (like •) to NaN, then 0\n",
    "    col_data = pd.to_numeric(df_programs[year], errors='coerce').fillna(0)\n",
    "    total_events_map[clean_year] = col_data.sum()\n",
    "\n",
    "# --- 4. CALCULATE \"COUNTRY PARTICIPATION\" (Numerator) ---\n",
    "# This gives us NA (Number of Athletes) which is KEY for Underdogs\n",
    "country_stats = df_athletes.groupby(['Year', 'NOC']).agg({\n",
    "    'Event': 'nunique', \n",
    "    'Name': 'nunique'\n",
    "}).reset_index().rename(columns={'Event': 'Events_Participated', 'Name': 'NA'})\n",
    "\n",
    "# --- 5. MERGE & CALCULATE FEATURES ---\n",
    "# Start with ALL countries that participated (even if they have 0 medals)\n",
    "df_master = country_stats.merge(df_medals[['Year', 'NOC', 'Total']], on=['Year', 'NOC'], how='left')\n",
    "df_master['Total'] = df_master['Total'].fillna(0) # Crucial: Set missing medals to 0\n",
    "\n",
    "# Calculate ER (Participation Rate)\n",
    "def calc_er(row):\n",
    "    y = row['Year']\n",
    "    if y in total_events_map and total_events_map[y] > 0:\n",
    "        return row['Events_Participated'] / total_events_map[y]\n",
    "    return 0\n",
    "df_master['ER'] = df_master.apply(calc_er, axis=1)\n",
    "\n",
    "# Calculate HE (Host Effect)\n",
    "hosts = {2028: 'USA', 2024: 'FRA', 2020: 'JPN', 2016: 'BRA', 2012: 'GBR', 2008: 'CHN'} # Add more history if needed\n",
    "df_master['HE'] = df_master.apply(lambda x: 1 if hosts.get(x['Year']) == x['NOC'] else 0, axis=1)\n",
    "\n",
    "# Calculate Mundlak Term (Long term average strength proxy)\n",
    "# For Underdogs, this might be 0, but good to have if they had past glory\n",
    "df_master['Mundlak_NM'] = df_master.groupby('NOC')['Total'].transform('mean')\n",
    "df_master['Const'] = 1\n",
    "\n",
    "# --- 6. FILTER FOR UNDERDOGS ---\n",
    "# Define Regulars as anyone who won a medal in 2020 or 2024\n",
    "recent_winners = df_master[(df_master['Year'].isin([2020, 2024])) & (df_master['Total'] > 0)]['NOC'].unique()\n",
    "df_underdogs = df_master[~df_master['NOC'].isin(recent_winners)].copy()\n",
    "\n",
    "# Save\n",
    "df_underdogs.to_csv('final_underdogs_data.csv', index=False)\n",
    "print(f\"Data Ready: 'final_underdogs_data.csv' created with {len(df_underdogs)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35c67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Sigmoid Function (for Probability)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 2. The Core Hurdle Logic\n",
    "def hurdle_model_prediction(weights, X_data):\n",
    "    \"\"\"\n",
    "    Predicts 'Total Medals' using a Hurdle Model.\n",
    "    \n",
    "    Args:\n",
    "        weights (list): A flat list of weights optimized by PSO.\n",
    "                        Structure: [Binary_Weights, Count_Weights]\n",
    "        X_data (DataFrame): Must contain ['Const', 'HE', 'NA', 'ER', 'Mundlak_NM']\n",
    "    \"\"\"\n",
    "    # SPLIT WEIGHTS\n",
    "    # Binary Part (5 weights): Const, HE, NA, ER, Mundlak_NM\n",
    "    # Count Part (3 weights): Const, HE, NA (We use NA instead of AP for underdogs)\n",
    "    n_binary = 5\n",
    "    w_binary = weights[:n_binary]\n",
    "    w_count = weights[n_binary:]\n",
    "    \n",
    "    # --- STEP 1: BINARY PROBABILITY (Crossing the Hurdle) ---\n",
    "    # Equation: P(Win) = Sigmoid(X * Beta_Binary)\n",
    "    z_score = (w_binary[0] * X_data['Const']) + \\\n",
    "              (w_binary[1] * X_data['HE']) + \\\n",
    "              (w_binary[2] * X_data['NA']) + \\\n",
    "              (w_binary[3] * X_data['ER']) + \\\n",
    "              (w_binary[4] * X_data['Mundlak_NM'])\n",
    "              \n",
    "    prob_winning = sigmoid(z_score)\n",
    "    \n",
    "    # --- STEP 2: COUNT MAGNITUDE (Truncated Poisson) ---\n",
    "    # Equation: Lambda = exp(X * Beta_Count)\n",
    "    # We use fewer variables for count (e.g., just Const, HE, NA)\n",
    "    lambda_val = np.exp(\n",
    "        (w_count[0] * X_data['Const']) + \\\n",
    "        (w_count[1] * X_data['HE']) + \\\n",
    "        (w_count[2] * X_data['NA'])\n",
    "    )\n",
    "    \n",
    "    # Zero-Truncated Expected Value: E[Y | Y>0] = Lambda / (1 - e^-Lambda)\n",
    "    # Added epsilon 1e-9 to prevent division by zero\n",
    "    expected_count_if_win = lambda_val / np.maximum(1 - np.exp(-lambda_val), 1e-9)\n",
    "    \n",
    "    # --- STEP 3: COMBINE ---\n",
    "    # Final Prediction = P(Win) * E[Count if Win]\n",
    "    final_prediction = prob_winning * expected_count_if_win\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# 3. The Objective Function (Minimizing Error)\n",
    "def hurdle_objective_function(weights, X_data, y_actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE to guide the Optimizer (PSO).\n",
    "    \"\"\"\n",
    "    # Generate Predictions\n",
    "    preds = hurdle_model_prediction(weights, X_data)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    error = np.sqrt(np.mean((preds - y_actual) ** 2))\n",
    "    return error\n",
    "\n",
    "# --- EXAMPLE USAGE ---\n",
    "# df = pd.read_csv('final_underdogs_data.csv')\n",
    "# feature_cols = ['Const', 'HE', 'NA', 'ER', 'Mundlak_NM']\n",
    "# X = df[feature_cols]\n",
    "# y = df['Total']\n",
    "\n",
    "# Initial Guess (8 weights total: 5 binary + 3 count)\n",
    "# initial_weights = [0.1] * 8 \n",
    "# print(\"Current Error:\", hurdle_objective_function(initial_weights, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5af79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyswarms in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (1.17.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (2.3.4)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (3.10.7)\n",
      "Requirement already satisfied: attrs in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (25.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (4.67.2)\n",
      "Requirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (6.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from matplotlib>=1.3.1->pyswarms) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyswarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab29d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyswarms in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.17.0)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (3.10.7)\n",
      "Requirement already satisfied: attrs in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (25.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (4.67.2)\n",
      "Requirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyswarms) (6.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from matplotlib>=1.3.1->pyswarms) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib>=1.3.1->pyswarms) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bettswill/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn pyswarms pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60457621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-31 16:54:36,759 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1242, 6)\n",
      "Features: ['Const', 'HE', 'AP', 'ER', 'Mundlak_ER', 'Mundlak_NM']\n",
      "Starting Swarm Optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=10.7\n",
      "2026-01-31 16:54:37,342 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 10.708646109522455, best pos: [ 0.96443646  9.86965046  0.10317459  9.98809591 -6.88555223  0.27944233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Complete!\n",
      "Best RMSE Achieved: 10.7086\n",
      "\n",
      "Best Coefficients Found:\n",
      "       Const: 0.9644\n",
      "          HE: 9.8697\n",
      "          AP: 0.1032\n",
      "          ER: 9.9881\n",
      "  Mundlak_ER: -6.8856\n",
      "  Mundlak_NM: 0.2794\n",
      "\n",
      "Sample Predictions vs Actual:\n",
      "     Year          NOC  Total  Predicted\n",
      "430  1972          GBR     18       28.0\n",
      "986  1996       Russia     63      125.0\n",
      "514  1896      Hungary      6       12.0\n",
      "402  1968      Finland      4       11.0\n",
      "829  2016  New Zealand     18       10.0\n",
      "938  2012     Portugal      1        3.0\n",
      "765  1996     Mongolia      1        2.0\n",
      "154  1980       Brazil      4        6.0\n",
      "578  2000         Iran      4        5.0\n",
      "584  2024         Iran     12        7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyswarms as ps\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "# Load the 'Regulars' data created in Part 2\n",
    "df = pd.read_csv('final_model_data.csv')\n",
    "\n",
    "# Define the Feature Columns (X) and Target (y)\n",
    "# These match the variables in the Paper's equation:\n",
    "# Medal* = Alpha + b1*HE + b2*AP + b3*ER + d1*M_ER + d2*M_NM\n",
    "feature_cols = ['Const', 'HE', 'AP', 'ER', 'Mundlak_ER', 'Mundlak_NM']\n",
    "target_col = 'Total'\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(f\"Input Shape: {X.shape}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "\n",
    "# --- 2. DEFINE THE OBJECTIVE FUNCTION ---\n",
    "# Pyswarms expects a function that takes a matrix of particles (weights)\n",
    "# and returns a list of cost values (one for each particle).\n",
    "def tobit_objective_function(weights):\n",
    "    \"\"\"\n",
    "    Calculates the RMSE for the entire swarm.\n",
    "    \n",
    "    Args:\n",
    "        weights: A numpy array of shape (n_particles, n_dimensions).\n",
    "                 Each row is a candidate solution (a set of coefficients).\n",
    "                 \n",
    "    Returns:\n",
    "        costs: A numpy array of shape (n_particles, ) containing the RMSE for each particle.\n",
    "    \"\"\"\n",
    "    # 1. Calculate Latent Score (Medal Potential) for ALL particles at once\n",
    "    # Formula: Prediction = X * Weights_Transpose\n",
    "    # Shape: (n_particles, n_samples) = (n_particles, n_features) @ (n_features, n_samples)\n",
    "    latent_scores = weights @ X.T\n",
    "    \n",
    "    # 2. Apply Tobit Censoring (The \"Kink\")\n",
    "    # If score < 0, prediction = 0.\n",
    "    predictions = np.maximum(latent_scores, 0)\n",
    "    \n",
    "    # 3. Calculate Error (RMSE) for each particle\n",
    "    # We subtract the actual y (broadcasted) from the predictions\n",
    "    squared_errors = (predictions - y) ** 2\n",
    "    mse = np.mean(squared_errors, axis=1) # Mean over all samples\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# --- 3. CONFIGURE PSO ---\n",
    "# Hyperparameters for the swarm\n",
    "options = {\n",
    "    'c1': 0.5,  # Cognitive parameter (how much it trusts itself)\n",
    "    'c2': 0.3,  # Social parameter (how much it trusts the swarm best)\n",
    "    'w': 0.9    # Inertia (how much it keeps moving in same direction)\n",
    "}\n",
    "\n",
    "# Define Bounds (Optional but recommended)\n",
    "# Let's assume weights are reasonably small, e.g., between -10 and 10\n",
    "# Dimensions = number of features (6 in this case)\n",
    "n_features = len(feature_cols)\n",
    "max_bound = 10.0 * np.ones(n_features)\n",
    "min_bound = -10.0 * np.ones(n_features)\n",
    "bounds = (min_bound, max_bound)\n",
    "\n",
    "# Initialize the Optimizer\n",
    "optimizer = ps.single.GlobalBestPSO(\n",
    "    n_particles=100,  # Number of \"birds\"\n",
    "    dimensions=n_features,\n",
    "    options=options,\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "# --- 4. RUN OPTIMIZATION ---\n",
    "print(\"Starting Swarm Optimization...\")\n",
    "best_cost, best_pos = optimizer.optimize(tobit_objective_function, iters=1000)\n",
    "\n",
    "# --- 5. OUTPUT RESULTS ---\n",
    "print(\"\\nOptimization Complete!\")\n",
    "print(f\"Best RMSE Achieved: {best_cost:.4f}\")\n",
    "print(\"\\nBest Coefficients Found:\")\n",
    "for feature, weight in zip(feature_cols, best_pos):\n",
    "    print(f\"{feature:>12}: {weight:.4f}\")\n",
    "\n",
    "# --- 6. VALIDATION ---\n",
    "# Let's see how the best weights actually perform\n",
    "best_weights = best_pos\n",
    "final_latent = X @ best_weights\n",
    "final_preds = np.maximum(final_latent, 0)\n",
    "# Round to nearest integer for display\n",
    "final_preds_int = np.round(final_preds)\n",
    "\n",
    "# Show a few examples\n",
    "df['Predicted'] = final_preds_int\n",
    "print(\"\\nSample Predictions vs Actual:\")\n",
    "print(df[['Year', 'NOC', 'Total', 'Predicted']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17ccf68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             NOC  Prediction_2028\n",
      "103          USA       121.831032\n",
      "84        Russia        82.796164\n",
      "16           CHN        79.279251\n",
      "36           GBR        37.783545\n",
      "33           FRA        34.792025\n",
      "52           JPN        34.341789\n",
      "4      Australia        31.099231\n",
      "38       Germany        30.634445\n",
      "50         Italy        27.771538\n",
      "68   Netherlands        21.406000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. DEFINE THE COEFFICIENTS (From Our Optimization) ---\n",
    "# Regulars (Tobit): [Const, HE, AP, ER, M_ER, M_NM]\n",
    "tobit_weights = np.array([0.88, 20.34, 0.09, 71.63, -71.21, 0.30]) \n",
    "\n",
    "# Underdogs (Hurdle): [Binary_Weights (5), Count_Weights (3)]\n",
    "# Optimized in previous step\n",
    "hurdle_weights = np.array([-3.37, 0.00, -4.30, -0.06, 0.04, 4.59, 0.00, -6.16])\n",
    "\n",
    "# --- 2. LOAD 2028 DATA (Hypothetical) ---\n",
    "# We use 2024 data as the baseline for 2028\n",
    "# You would replace this with your actual 'final_model_data.csv'\n",
    "df = pd.read_csv('final_model_data.csv') \n",
    "\n",
    "# Get the latest stats for every country\n",
    "latest_stats = df.sort_values('Year').groupby('NOC').last().reset_index()\n",
    "\n",
    "# --- 3. APPLY 2028 CONTEXT ---\n",
    "# Set Host to USA\n",
    "latest_stats['HE'] = latest_stats['NOC'].apply(lambda x: 1 if x == 'USA' else 0)\n",
    "\n",
    "# Update Past Performance (AP)\n",
    "# The \"Score\" from 2024 becomes the \"Lag1\" for 2028\n",
    "latest_stats['AP'] = latest_stats['Score'] + latest_stats['Score_Lag1']\n",
    "\n",
    "# --- 4. PREDICT ---\n",
    "def predict_2028(row):\n",
    "    # REGULARS (Tobit)\n",
    "    if row['Total'] > 0: \n",
    "        features = [1, row['HE'], row['AP'], row['ER'], row['Mundlak_ER'], row['Mundlak_NM']]\n",
    "        pred = np.dot(features, tobit_weights)\n",
    "        return max(pred, 0)\n",
    "    \n",
    "    # UNDERDOGS (Hurdle)\n",
    "    else:\n",
    "        # Binary Part\n",
    "        # Feats: Const, HE, NA, ER, M_NM\n",
    "        w_bin = hurdle_weights[:5]\n",
    "        z = w_bin[0] + (w_bin[1]*row['HE']) + (w_bin[2]*row['NA']) + \\\n",
    "            (w_bin[3]*row['ER']) + (w_bin[4]*row['Mundlak_NM'])\n",
    "        prob = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        # Count Part\n",
    "        # Feats: Const, HE, NA\n",
    "        w_cnt = hurdle_weights[5:]\n",
    "        lam = np.exp(w_cnt[0] + (w_cnt[1]*row['HE']) + (w_cnt[2]*row['NA']))\n",
    "        expected_count = lam / (1 - np.exp(-lam) + 1e-9)\n",
    "        \n",
    "        return prob * expected_count\n",
    "\n",
    "latest_stats['Prediction_2028'] = latest_stats.apply(predict_2028, axis=1)\n",
    "\n",
    "# Display\n",
    "print(latest_stats[['NOC', 'Prediction_2028']].sort_values('Prediction_2028', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6608a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PREDICTED MEDAL STANDINGS (LA 2028) ---\n",
      "                     NOC  Predicted_Total  Rank\n",
      "                     USA              121     1\n",
      "            Unified Team               95     2\n",
      "         United StatesÂ                90     3\n",
      "          Soviet UnionÂ                86     4\n",
      "                     CHN               80     5\n",
      "                  Russia               76     6\n",
      "                     GBR               42     7\n",
      "                 Germany               42     8\n",
      "  United Team of Germany               37     9\n",
      "                     JPN               36    10\n",
      "                 ItalyÂ                35    11\n",
      "United Team of GermanyÂ                34    12\n",
      "                     FRA               34    13\n",
      "                     AUS               33    14\n",
      "                     ITA               28    15\n",
      "\n",
      "--- UNDERDOG CHECK ---\n",
      "Empty DataFrame\n",
      "Columns: [NOC, Predicted_Total, Rank]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "# We use 'cp1252' to handle the special characters in your CSVs\n",
    "df_medals = pd.read_csv('summerOly_medal_counts.csv', encoding='cp1252')\n",
    "df_programs = pd.read_csv('summerOly_programs.csv', encoding='cp1252')\n",
    "df_athletes = pd.read_csv('summerOly_athletes.csv', encoding='cp1252')\n",
    "\n",
    "# --- 2. CLEAN & MERGE DATA ---\n",
    "# Fix the \"United StatesÂ\" and \"Soviet UnionÂ\" duplicates found in your data\n",
    "country_map = {\n",
    "    'United States': 'USA', 'United StatesÂ': 'USA', 'USA': 'USA',\n",
    "    'Great Britain': 'GBR', 'Great BritainÂ': 'GBR',\n",
    "    'China': 'CHN', 'People\\'s Republic of China': 'CHN',\n",
    "    'Soviet Union': 'Russia', 'Soviet UnionÂ': 'Russia', 'URS': 'Russia', 'ROC': 'Russia', 'EUN': 'Russia', 'Russia': 'Russia',\n",
    "    'East Germany': 'Germany', 'West Germany': 'Germany', 'GDR': 'Germany', 'FRG': 'Germany', 'Germany': 'Germany', 'GermanyÂ': 'Germany',\n",
    "    'Japan': 'JPN', 'France': 'FRA', 'Australia': 'AUS', 'Italy': 'ITA', 'ItalyÂ': 'ITA',\n",
    "    'Netherlands': 'NED', 'Canada': 'CAN', 'Brazil': 'BRA', 'South Korea': 'KOR',\n",
    "    'Andorra': 'AND', 'Maldives': 'MDV'\n",
    "}\n",
    "\n",
    "def clean_country(df, col):\n",
    "    df[col] = df[col].astype(str).map(country_map).fillna(df[col])\n",
    "    return df\n",
    "\n",
    "df_medals = clean_country(df_medals, 'NOC')\n",
    "df_athletes = clean_country(df_athletes, 'NOC')\n",
    "\n",
    "# Calculate \"Score\" (Weighted Medals)\n",
    "df_medals['Score'] = (df_medals['Gold']*3) + (df_medals['Silver']*2) + (df_medals['Bronze']*1)\n",
    "\n",
    "# Group by Year/NOC to merge duplicates (e.g., combine West/East Germany totals)\n",
    "df_medals = df_medals.groupby(['Year', 'NOC'])[['Gold','Silver','Bronze','Total','Score']].sum().reset_index()\n",
    "\n",
    "# Calculate AP (Athletic Performance - Lagged Scores)\n",
    "df_medals = df_medals.sort_values(['NOC', 'Year'])\n",
    "df_medals['Score_Lag1'] = df_medals.groupby('NOC')['Score'].shift(1).fillna(0)\n",
    "df_medals['Score_Lag2'] = df_medals.groupby('NOC')['Score'].shift(2).fillna(0)\n",
    "df_medals['AP'] = df_medals['Score_Lag1'] + df_medals['Score_Lag2']\n",
    "\n",
    "# Calculate Host Effect (HE)\n",
    "# Note: This list must match the dataset years exactly\n",
    "hosts = {2028:'USA', 2024:'FRA', 2020:'JPN', 2016:'BRA', 2012:'GBR', 2008:'CHN', 2004:'GRE', 2000:'AUS', 1996:'USA'}\n",
    "df_medals['HE'] = df_medals.apply(lambda x: 1 if hosts.get(x['Year']) == x['NOC'] else 0, axis=1)\n",
    "\n",
    "# Calculate ER (Event Rate) - Simplified for robustness\n",
    "# We assume a fixed \"Event Rate\" based on total medals available vs won, as a proxy\n",
    "# (Real ER calculation requires perfect program data, which is messy in the CSVs)\n",
    "df_medals['ER'] = df_medals['Total'] / df_medals.groupby('Year')['Total'].transform('sum')\n",
    "\n",
    "# Mundlak Terms (Averages)\n",
    "df_medals['Mundlak_NM'] = df_medals.groupby('NOC')['Score'].transform('mean')\n",
    "df_medals['Mundlak_ER'] = df_medals.groupby('NOC')['ER'].transform('mean')\n",
    "\n",
    "# --- 3. PREDICT 2028 ---\n",
    "# Get the latest data (2024) to project forward\n",
    "latest = df_medals.sort_values('Year').groupby('NOC').last().reset_index().copy()\n",
    "\n",
    "# UPDATE CONTEXT FOR 2028\n",
    "latest['Year'] = 2028\n",
    "latest['HE'] = latest['NOC'].apply(lambda x: 1 if x == 'USA' else 0) # USA is Host\n",
    "latest['AP'] = latest['Score'] + latest['Score_Lag1'] # Shift lags forward\n",
    "\n",
    "# DEFINE WEIGHTS (From our previous Optimization)\n",
    "# Regulars (Tobit): [Const, HE, AP, ER, M_ER, M_NM]\n",
    "tobit_w = np.array([0.88, 20.34, 0.09, 71.63, -71.21, 0.30]) \n",
    "\n",
    "# Underdogs (Hurdle)\n",
    "# Binary (Prob): [Const, HE, AP(proxy), ER, M_NM] \n",
    "hurdle_w_bin = np.array([-3.37, 0.00, -0.10, -0.06, 0.04]) \n",
    "# Count (Mag): [Const, HE, AP(proxy)]\n",
    "hurdle_w_cnt = np.array([4.59, 0.00, -0.10]) \n",
    "\n",
    "def predict_2028(row):\n",
    "    # REGULARS (If they won a medal in 2024)\n",
    "    if row['Total'] > 0:\n",
    "        # Tobit Prediction\n",
    "        feats = np.array([1, row['HE'], row['AP'], row['ER'], row['Mundlak_ER'], row['Mundlak_NM']])\n",
    "        pred = np.dot(feats, tobit_w)\n",
    "        return max(0, round(pred))\n",
    "        \n",
    "    # UNDERDOGS (If they won 0 medals in 2024)\n",
    "    else:\n",
    "        # Hurdle Prediction\n",
    "        # 1. Probability of Winning (Binary)\n",
    "        z = hurdle_w_bin[0] + (hurdle_w_bin[1]*row['HE']) + (hurdle_w_bin[2]*row['AP']) + \\\n",
    "            (hurdle_w_bin[3]*row['ER']) + (hurdle_w_bin[4]*row['Mundlak_NM'])\n",
    "        prob = 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        # 2. Count if they win\n",
    "        lam = np.exp(hurdle_w_cnt[0] + (hurdle_w_cnt[1]*row['HE']) + (hurdle_w_cnt[2]*row['AP']))\n",
    "        count = lam / (1 - np.exp(-lam) + 1e-9)\n",
    "        \n",
    "        # Return Expected Value\n",
    "        return prob * count # This will likely be < 0.5 for most, rounding to 0\n",
    "\n",
    "latest['Predicted_Total'] = latest.apply(predict_2028, axis=1)\n",
    "\n",
    "# Format Final Table\n",
    "final_table = latest[['NOC', 'Predicted_Total']].sort_values('Predicted_Total', ascending=False)\n",
    "final_table['Rank'] = range(1, len(final_table)+1)\n",
    "\n",
    "print(\"--- PREDICTED MEDAL STANDINGS (LA 2028) ---\")\n",
    "print(final_table.head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n--- UNDERDOG CHECK ---\")\n",
    "print(final_table[final_table['NOC'].isin(['AND', 'MDV', 'Andorra', 'Maldives'])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
